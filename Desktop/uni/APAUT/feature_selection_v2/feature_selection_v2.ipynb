{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "In this practical, you will become familiarized with some basic feature selection methods implemented in scikit-learn. Consider the prostate dataset that is attached to this practical. You are asked to:\n",
    "\n",
    "1. Estimate the performance of the nearest neighbor classifier on this dataset using 10-fold cross validation when all the features are used for prediction. The number of neighbors should be chosen using an inner cross-validation procedure. You can use 5-fold cross validation for this.\n",
    "\n",
    "2. Estimate the performance of the nearest neighbor classifier on the same dataset when using a feature selection technique based on the F-score (ANOVA) that picks up the 10 most relevant features. Use the same cross-validation methods as in the previous step.\n",
    "\n",
    "3. Repeat the previous experiment but when a random forest is used to pick up the 10 most relevant features. Use an initial filtering method based on the F-score to keep only the 20% most promising features.\n",
    "\n",
    "4. What feature selection method performs best? Can you explain why?\n",
    "\n",
    "Now we will address the problem of analyzing the trade-off between interpretability and prediction accuracy. For this, you are asked to:\n",
    "\n",
    "1. Estimate the performance of the nearest neighbor classifier with K=3 as a function of the features used for prediction. Use a 10-times 10-fold cross-validation method and plot the results obtained. That is prediction error vs. the number of features used for prediction. Use the F-score for feature selection. Report results from 1 feature to 200 features. Not all features need to be explored. Use a higher resolution when you are closer to 1 feature.\n",
    "\n",
    "2. Repeat that process when the feature selection is done externally to the cross-validation loop using all the available data. Include these results in the previous plot.\n",
    "3. Are the two estimates obtained similar? What are their differences? If they are different try to explain why this is the case.\n",
    "\n",
    "4. By taking a look at these results, what is the optimal number of features to use in this dataset?\n",
    "\n",
    "5. Given the results obtained in this part of the practical, you are asked to indicate which particular features should be used for prediction on this dataset. Include a list with them. Take a look at the documentation of SelectKBest from scikit-learn to understand how to do this. Use all available data to provide such a list of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "import seaborn as sns; sns.set()\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "from scipy import linalg\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix, classification_report, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Estimate the performance of the nearest neighbor classifier on this dataset using 10-fold cross validation when all the features are used for prediction. The number of neighbors should be chosen using an inner cross-validation procedure. You can use 5-fold cross validation for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response 1\n",
    "\n",
    "We obtain a Mean Error of $0.211$ with std mean error of $0.012$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_neighbors = [1, 3, 5, 7, 11, 15, 20, 25, 30]\n",
    "\n",
    "def get_scaler(X_train):\n",
    "    return preprocessing.StandardScaler().fit(X_train)\n",
    "    \n",
    "def make_grid(n_splits):\n",
    "    pipeline = Pipeline([ ('knn', KNeighborsClassifier()) ])\n",
    "    param_grid = { 'knn__n_neighbors': N_neighbors }\n",
    "    skfold = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=1, random_state=0)\n",
    "    gridcv = GridSearchCV(pipeline, cv=skfold, n_jobs=1, param_grid=param_grid, scoring=make_scorer(accuracy_score))\n",
    "    return gridcv\n",
    "\n",
    "def estimate_n_neighbors(X_train, y_train, X_test, y_test, gridcv, do_plot=False, verbose=True):\n",
    "    result = gridcv.fit(X_train, y_train)\n",
    "    accuracies = gridcv.cv_results_['mean_test_score']\n",
    "    std_accuracies = gridcv.cv_results_['std_test_score']\n",
    "    N_neighbors_selected = N_neighbors[np.argmax(accuracies)]\n",
    "    if do_plot:\n",
    "        test_accuracies = np.ones(len(N_neighbors))\n",
    "        for i in range(len(N_neighbors)):\n",
    "            knn = KNeighborsClassifier(n_neighbors = N_neighbors[ i ])\n",
    "            knn.fit(X_train, y_train)\n",
    "            test_accuracies[ i ] = accuracy_score(knn.predict(X_test), y_test)\n",
    "        plt.figure()\n",
    "        line1, = plt.plot(N_neighbors, accuracies, 'o-', color=\"g\")\n",
    "        line2, = plt.plot(N_neighbors, test_accuracies, 'x-', color=\"r\")\n",
    "        plt.fill_between(N_neighbors, accuracies - std_accuracies / np.sqrt(10), \\\n",
    "            accuracies + std_accuracies / np.sqrt(10), alpha=0.1, color=\"g\")\n",
    "        plt.grid()\n",
    "        plt.title(\"Different number of neighbors for KNN\")\n",
    "        plt.xlabel('Number of neighbors')\n",
    "        plt.xticks(np.array(N_neighbors))\n",
    "        plt.ylabel('Prostate Cancer - Classification Accuracy')\n",
    "        plt.ylim((0.5, 1.0))\n",
    "        legend_handles = [ mlines.Line2D([], [], color='g', marker='o', \\\n",
    "                                  markersize=15, label='CV-estimate'), \\\n",
    "                        mlines.Line2D([], [], color='r', marker='x', \\\n",
    "                                  markersize=15, label='Test set estimate')]\n",
    "        plt.legend(handles=legend_handles, loc = 3)\n",
    "        plt.show()\n",
    "    \n",
    "    if verbose: print(\"Selected optimal number of neighbors\", N_neighbors_selected)\n",
    "    return N_neighbors_selected    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('prostate.csv', header = 0)\n",
    "X = data.values[ :, 0:-1].astype(np.float)\n",
    "y = (data.values[ :, -1] == 1).astype(np.int)\n",
    "\n",
    "# Construct pipeline for n_neighbors inner estimation\n",
    "gridcv = make_grid(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 12625\n",
      "Partition 0\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 1\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 2\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 3\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 4\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 5\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 6\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 7\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 8\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 9\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 11\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 12\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 13\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 14\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 15\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 16\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 17\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 18\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 19\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 20\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 21\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 22\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 23\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 24\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 25\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 26\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 27\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 28\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 29\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 30\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 31\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 32\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 33\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 34\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 35\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 36\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 37\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 38\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 39\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 40\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 41\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 42\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 43\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 44\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 45\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 46\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 47\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 48\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 49\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 50\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 51\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 52\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 53\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 54\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 55\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 56\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 57\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 58\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 59\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 60\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 61\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 62\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 63\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 64\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 65\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 66\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 67\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 68\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 69\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 70\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 71\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 72\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 73\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 74\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 75\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 76\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 77\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 78\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 79\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 80\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 81\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 82\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 83\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 84\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 85\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 86\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 87\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 88\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 89\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 90\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 91\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 92\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 93\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 94\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 95\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 96\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 97\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 98\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 99\n",
      "Selected optimal number of neighbors 7\n",
      "\n",
      "Errors [0.27272727 0.18181818 0.1        0.2        0.         0.4\n",
      " 0.2        0.2        0.4        0.1        0.18181818 0.18181818\n",
      " 0.5        0.1        0.2        0.1        0.5        0.3\n",
      " 0.3        0.         0.27272727 0.36363636 0.3        0.3\n",
      " 0.3        0.1        0.1        0.2        0.3        0.2\n",
      " 0.36363636 0.54545455 0.2        0.3        0.2        0.2\n",
      " 0.2        0.         0.1        0.1        0.09090909 0.27272727\n",
      " 0.2        0.3        0.2        0.2        0.2        0.2\n",
      " 0.1        0.3        0.         0.18181818 0.         0.3\n",
      " 0.3        0.2        0.1        0.2        0.1        0.4\n",
      " 0.18181818 0.         0.2        0.         0.3        0.4\n",
      " 0.3        0.3        0.1        0.3        0.27272727 0.36363636\n",
      " 0.1        0.1        0.3        0.2        0.1        0.5\n",
      " 0.1        0.1        0.18181818 0.27272727 0.1        0.1\n",
      " 0.2        0.3        0.4        0.1        0.3        0.3\n",
      " 0.18181818 0.         0.2        0.2        0.2        0.3\n",
      " 0.3        0.2        0.2        0.        ]\n",
      "\n",
      "Mean 0.21163636363636365 std mean error 0.012111110942620535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating performance for all features\n",
    "(_, n_features) = X.shape\n",
    "print(\"Number of features\", n_features)\n",
    "n_splits = 10\n",
    "n_repeats = 10\n",
    "random_state = 1\n",
    "rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "split = 0\n",
    "knn_errors = np.zeros(n_splits * n_repeats)\n",
    "for train_index, test_index in rkf.split(X, y):\n",
    "    print(\"Partition\", split)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = get_scaler(X_train)\n",
    "    scaler.fit(X_train, y_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Compute hyperparam\n",
    "    n_neighbors = estimate_n_neighbors(X_train_scaled, y_train, X_test_scaled, y_test,\\\n",
    "                                       gridcv, do_plot=False, verbose=True)\n",
    "    # Training & Scoring\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    knn_errors[split] = 1.0 - np.mean(knn.predict(X_test_scaled) == y_test)\n",
    "    split += 1\n",
    "print()\n",
    "print(\"Errors\", knn_errors)\n",
    "print()\n",
    "print(\"Mean\", knn_errors.mean(), \"std mean error\", (np.std(knn_errors) / np.sqrt(len(knn_errors))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Estimate the performance of the nearest neighbor classifier on the same dataset when using a feature selection technique based on the F-score (ANOVA) that picks up the 10 most relevant features. Use the same cross-validation methods as in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response 2\n",
    "\n",
    "We obtain a Mean Error of $0.088$ with std mean error of $0.008$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 10\n",
      "Partition 0\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 1\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 2\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 3\n",
      "Selected optimal number of neighbors 25\n",
      "Partition 4\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 5\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 6\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 7\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 8\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 9\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 11\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 12\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 13\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 14\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 15\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 16\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 17\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 18\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 19\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 20\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 21\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 22\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 23\n",
      "Selected optimal number of neighbors 30\n",
      "Partition 24\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 25\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 26\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 27\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 28\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 29\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 30\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 31\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 32\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 33\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 34\n",
      "Selected optimal number of neighbors 30\n",
      "Partition 35\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 36\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 37\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 38\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 39\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 40\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 41\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 42\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 43\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 44\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 45\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 46\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 47\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 48\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 49\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 50\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 51\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 52\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 53\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 54\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 55\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 56\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 57\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 58\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 59\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 60\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 61\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 62\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 63\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 64\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 65\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 66\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 67\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 68\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 69\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 70\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 71\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 72\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 73\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 74\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 75\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 76\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 77\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 78\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 79\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 80\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 81\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 82\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 83\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 84\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 85\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 86\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 87\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 88\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 89\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 90\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 91\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 92\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 93\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 94\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 95\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 96\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 97\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 98\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 99\n",
      "Selected optimal number of neighbors 15\n",
      "Errors [0.09090909 0.09090909 0.1        0.         0.1        0.\n",
      " 0.1        0.2        0.1        0.1        0.         0.09090909\n",
      " 0.         0.1        0.1        0.1        0.         0.\n",
      " 0.2        0.1        0.18181818 0.         0.1        0.3\n",
      " 0.         0.         0.         0.2        0.1        0.2\n",
      " 0.09090909 0.09090909 0.         0.         0.2        0.\n",
      " 0.         0.1        0.         0.3        0.36363636 0.09090909\n",
      " 0.         0.1        0.         0.         0.1        0.2\n",
      " 0.1        0.1        0.         0.18181818 0.2        0.1\n",
      " 0.         0.2        0.1        0.         0.1        0.\n",
      " 0.18181818 0.18181818 0.1        0.1        0.         0.1\n",
      " 0.         0.1        0.         0.1        0.09090909 0.27272727\n",
      " 0.1        0.1        0.         0.         0.2        0.1\n",
      " 0.         0.         0.09090909 0.09090909 0.         0.1\n",
      " 0.2        0.1        0.1        0.         0.         0.1\n",
      " 0.09090909 0.         0.2        0.         0.1        0.1\n",
      " 0.1        0.         0.1        0.2       ]\n",
      "\n",
      "Mean 0.0877272727272727 std mean error 0.008135601792671861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_features = 10\n",
    "print(\"Number of features\", n_features)\n",
    "n_splits = 10\n",
    "n_repeats = 10\n",
    "random_state = 2\n",
    "rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "split = 0\n",
    "knn_errors = np.zeros(n_splits * n_repeats)\n",
    "for train_index, test_index in rkf.split(X, y):\n",
    "    print(\"Partition\", split)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = get_scaler(X_train)\n",
    "    scaler.fit(X_train, y_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Filtering\n",
    "    filtering = SelectKBest(f_classif, k = n_features)\n",
    "    filtering.fit(X_train_scaled, y_train)\n",
    "    X_train_filtered = filtering.transform(X_train_scaled)\n",
    "    X_test_filtered = filtering.transform(X_test_scaled)\n",
    "    \n",
    "    # Compute hyperparam\n",
    "    n_neighbors = estimate_n_neighbors(X_train_filtered, y_train, X_test_filtered, y_test,\\\n",
    "                                       gridcv, do_plot=False, verbose=True)\n",
    "    # Training & Scoring\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train_filtered, y_train)\n",
    "    knn_errors[split] = 1.0 - np.mean(knn.predict(X_test_filtered) == y_test)\n",
    "    split += 1\n",
    "print(\"Errors\", knn_errors)\n",
    "print()\n",
    "print(\"Mean\", knn_errors.mean(), \"std mean error\", (np.std(knn_errors) / np.sqrt(len(knn_errors))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Repeat the previous experiment but when a random forest is used to pick up the 10 most relevant features. Use an initial filtering method based on the F-score to keep only the 20% most promising features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response 3\n",
    "\n",
    "We obtain a Mean Error of $0.080$ with std mean error of $0.008$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 10\n",
      "Partition 0\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 1\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 2\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 3\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 25\n",
      "Partition 4\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 5\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 6\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 7\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 8\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 9\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 10\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 11\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 12\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 13\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 14\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 15\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 16\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 17\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 18\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 19\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 20\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 21\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 22\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 23\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 24\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 25\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 26\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 27\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 28\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 29\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 30\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 31\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 32\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 33\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 34\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 35\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 36\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 37\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 38\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 39\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 40\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 41\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 42\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 43\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 44\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 45\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 46\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 47\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 48\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 49\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 50\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 51\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 52\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 53\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 54\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 55\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 56\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 57\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 58\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 59\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 60\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 61\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 62\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 63\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 64\n",
      "Features reduced to (first pass) 2525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 65\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 66\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 67\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 15\n",
      "Partition 68\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 69\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 70\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 71\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 72\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 73\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 74\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 75\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 1\n",
      "Partition 76\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 77\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 78\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 25\n",
      "Partition 79\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 80\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 81\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 82\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 83\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "Partition 84\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 85\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 20\n",
      "Partition 86\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 87\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 88\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 89\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 90\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 91\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 92\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 93\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 7\n",
      "Partition 94\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 95\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 30\n",
      "Partition 96\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 11\n",
      "Partition 97\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 98\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 3\n",
      "Partition 99\n",
      "Features reduced to (first pass) 2525\n",
      "Features reduced to (second pass) 10\n",
      "Selected optimal number of neighbors 5\n",
      "\n",
      "Errors [0.09090909 0.09090909 0.         0.         0.1        0.\n",
      " 0.1        0.1        0.         0.         0.         0.09090909\n",
      " 0.         0.         0.2        0.1        0.         0.\n",
      " 0.2        0.1        0.09090909 0.         0.2        0.1\n",
      " 0.         0.1        0.         0.2        0.1        0.2\n",
      " 0.09090909 0.09090909 0.         0.         0.1        0.1\n",
      " 0.         0.1        0.1        0.3        0.18181818 0.09090909\n",
      " 0.         0.2        0.         0.2        0.1        0.1\n",
      " 0.         0.2        0.         0.09090909 0.1        0.\n",
      " 0.         0.2        0.2        0.1        0.1        0.\n",
      " 0.18181818 0.         0.2        0.         0.         0.1\n",
      " 0.         0.1        0.         0.1        0.09090909 0.18181818\n",
      " 0.2        0.1        0.         0.2        0.1        0.1\n",
      " 0.         0.         0.09090909 0.09090909 0.         0.1\n",
      " 0.1        0.1        0.1        0.         0.         0.1\n",
      " 0.09090909 0.         0.1        0.         0.1        0.1\n",
      " 0.         0.         0.         0.4       ]\n",
      "\n",
      "Mean 0.08036363636363636 std mean error 0.007953085580322511\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_features = 10\n",
    "print(\"Number of features\", n_features)\n",
    "n_splits = 10\n",
    "n_repeats = 10\n",
    "random_state = 2\n",
    "rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "split = 0\n",
    "knn_errors = np.zeros(n_splits * n_repeats)\n",
    "rf_selection =  SelectFromModel(RandomForestClassifier(n_estimators = 2000,\\\n",
    "                                                       random_state = random_state), threshold = 0.0)\n",
    "for train_index, test_index in rkf.split(X, y):\n",
    "    print(\"Partition\", split)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = get_scaler(X_train)\n",
    "    scaler.fit(X_train, y_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Filtering pass 1 via F-score, only 20%\n",
    "    inner_features = X_train.shape[1]\n",
    "    features_to_retain = int(20*inner_features/100)\n",
    "    filtering = SelectKBest(f_classif, k = features_to_retain)\n",
    "    filtering.fit(X_train_scaled, y_train)\n",
    "    X_train_filtered_F = filtering.transform(X_train_scaled)\n",
    "    X_test_filtered_F = filtering.transform(X_test_scaled)\n",
    "    n_features_reduction_F = X_train_filtered_F.shape[1]\n",
    "    print(\"Features reduced to (first pass)\", n_features_reduction_F)\n",
    "    \n",
    "    # Filtering random forest\n",
    "    rf_selection.fit(X_train_filtered_F, y_train)\n",
    "    rf_selection.threshold = -1.0 * np.sort(-1.0 * rf_selection.estimator_.feature_importances_)[n_features-1]\n",
    "    X_train_filtered_F_R = rf_selection.transform(X_train_filtered_F)\n",
    "    X_test_filtered_F_R = rf_selection.transform(X_test_filtered_F)\n",
    "    n_features_reduction = X_train_filtered_F_R.shape[1]\n",
    "    print(\"Features reduced to (second pass)\", n_features_reduction)\n",
    "    \n",
    "     # Compute hyperparam\n",
    "    n_neighbors = estimate_n_neighbors(X_train_filtered_F_R, y_train, X_test_filtered_F_R, y_test,\\\n",
    "                                       gridcv, do_plot=False, verbose=True)\n",
    "    \n",
    "    # Training & Scoring\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train_filtered_F_R, y_train)\n",
    "    knn_errors[split] = 1.0 - np.mean(knn.predict(X_test_filtered_F_R) == y_test)\n",
    "    split += 1\n",
    "print()\n",
    "print(\"Errors\", knn_errors)\n",
    "print()\n",
    "print(\"Mean\", knn_errors.mean(), \"std mean error\", (np.std(knn_errors) / np.sqrt(len(knn_errors))))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "What feature selection method performs best? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response 4\n",
    "\n",
    "ANOVA performs marginally worst than Random Forest, with overlapping confidence intervals:\n",
    "\n",
    "- Anova $0.088 \\pm 0.008$.\n",
    "- Random Forest $0.080 \\pm 0.008$.\n",
    "\n",
    "Decision trees are prone to be more sticky to the data, because of his very hard dependences of initial selection nodes, because it chooses the best result at a given step, but does not ensure that this is the optimal decision of the whole route to the leaf node. Random forests mitigate this problem but the algorithm needs enough features in order to make more effective the randomization. Perhaps the number of features is too low in this case.\n",
    "\n",
    "In fact, if we rise the number of selected features to $20$, Random Forest get more advantage over Anova, but yet very slightly.\n",
    "\n",
    "- Anova $0.083 \\pm 0.008$.\n",
    "- Random Forest $0.074 \\pm 0.008$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "latex_metadata": {
     "hidden": "true"
    }
   },
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "latex_metadata": {
     "hidden": "true",
     "lexer": "bash"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook feature_selection_v2.ipynb to latex\n",
      "[NbConvertApp] Support files will be in feature_selection_v2_files/\n",
      "[NbConvertApp] Making directory feature_selection_v2_files\n",
      "[NbConvertApp] Writing 41604 bytes to feature_selection_v2.tex\n",
      "[NbConvertApp] Converting notebook feature_selection_v2.ipynb to html_with_toclenvs\n",
      "[NbConvertApp] Writing 371529 bytes to feature_selection_v2.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "jupyter nbconvert --to=latex --template=~/report.tplx feature_selection_v2.ipynb 1> /dev/null\n",
    "pdflatex -shell-escape feature_selection_v2 1> /dev/null\n",
    "jupyter nbconvert --to html_with_toclenvs feature_selection_v2.ipynb 1> /dev/null"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "latex_metadata": {
   "author": "Daniel Cerdn, Fernando Freire",
   "title": "Feature Selection"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
